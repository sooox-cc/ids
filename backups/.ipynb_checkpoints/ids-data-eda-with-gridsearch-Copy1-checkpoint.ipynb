{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf27e5c-2519-4ebe-acf0-3516d7df23e8",
   "metadata": {},
   "source": [
    "# Enhanced IDS ML Evaluation with Grid Search Optimization\n",
    " \n",
    "## This notebook evaluates ML algorithms with hyperparameter tuning for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744b6190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:04.193863Z",
     "iopub.status.busy": "2025-12-03T17:54:04.193708Z",
     "iopub.status.idle": "2025-12-03T17:54:04.795265Z",
     "shell.execute_reply": "2025-12-03T17:54:04.794537Z",
     "shell.execute_reply.started": "2025-12-03T17:54:04.193848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (7.1.3)\n",
      "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "✅ Memory optimization configured for kernel stability\n"
     ]
    }
   ],
   "source": [
    "# Install Required Packages\n",
    "get_ipython().run_line_magic('pip', 'install seaborn psutil memory_profiler scikit-learn matplotlib')\n",
    "\n",
    "# Memory optimization for Jupyter kernel stability\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Force garbage collection after each cell\n",
    "get_ipython().run_line_magic('load_ext', 'memory_profiler')\n",
    "\n",
    "# Set environment variables for better memory management\n",
    "os.environ['PYTHONUNBUFFERED'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '4'  # Limit OpenMP threads\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '4'\n",
    "os.environ['MKL_NUM_THREADS'] = '4'\n",
    "\n",
    "# Configure garbage collection to be more aggressive\n",
    "gc.set_threshold(700, 10, 10)\n",
    "\n",
    "print(\"✅ Memory optimization configured for kernel stability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d875faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:04.796075Z",
     "iopub.status.busy": "2025-12-03T17:54:04.795868Z",
     "iopub.status.idle": "2025-12-03T17:54:05.774918Z",
     "shell.execute_reply": "2025-12-03T17:54:05.774387Z",
     "shell.execute_reply.started": "2025-12-03T17:54:04.796050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "\n",
      "======================================================================\n",
      "SYSTEM INFO\n",
      "======================================================================\n",
      "CPU Cores: 12\n",
      "Total RAM: 31.26 GB\n",
      "Available RAM: 16.39 GB\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import math, time, random, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import psutil\n",
    "import os\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Import sklearn modules\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SYSTEM INFO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"CPU Cores: {os.cpu_count()}\")\n",
    "print(f\"Total RAM: {psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / (1024**3):.2f} GB\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e484be-1245-41c3-b5cf-17a5934697b3",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f01717a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:05.776054Z",
     "iopub.status.busy": "2025-12-03T17:54:05.775731Z",
     "iopub.status.idle": "2025-12-03T17:54:06.263646Z",
     "shell.execute_reply": "2025-12-03T17:54:06.263039Z",
     "shell.execute_reply.started": "2025-12-03T17:54:05.776033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Training set shape: (82332, 45)\n",
      "Testing set shape: (175341, 45)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "train = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "test = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
    "print(f\"Training set shape: {train.shape}\")\n",
    "print(f\"Testing set shape: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89238455-1f93-4f12-81fe-e9ecdbf902ca",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a34eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:06.264493Z",
     "iopub.status.busy": "2025-12-03T17:54:06.264298Z",
     "iopub.status.idle": "2025-12-03T17:54:06.341380Z",
     "shell.execute_reply": "2025-12-03T17:54:06.340769Z",
     "shell.execute_reply.started": "2025-12-03T17:54:06.264469Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (257673, 45)\n",
      "Categorical columns: 4\n",
      "Numeric columns: 41\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train and test sets\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "cols_cat = data.select_dtypes('object').columns\n",
    "cols_numeric = data._get_numeric_data().columns\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Categorical columns: {len(cols_cat)}\")\n",
    "print(f\"Numeric columns: {len(cols_numeric)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3ee848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:06.342376Z",
     "iopub.status.busy": "2025-12-03T17:54:06.342115Z",
     "iopub.status.idle": "2025-12-03T17:54:09.791954Z",
     "shell.execute_reply": "2025-12-03T17:54:09.791334Z",
     "shell.execute_reply.started": "2025-12-03T17:54:06.342351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing one-hot encoding...\n",
      "Shape after encoding: (257673, 197)\n"
     ]
    }
   ],
   "source": [
    "# Handle categorical values\n",
    "def Remove_dump_values(data, cols):\n",
    "    for col in cols:\n",
    "        data[col] = np.where(data[col] == '-', 'None', data[col])\n",
    "    return data\n",
    "\n",
    "cols = data.columns\n",
    "data_bin = Remove_dump_values(data, cols)\n",
    "\n",
    "# Remove unnecessary features\n",
    "data_bin = data_bin.drop(['id', 'attack_cat'], axis=1)\n",
    "cols_cat = cols_cat.drop(['attack_cat'])\n",
    "\n",
    "# One-hot encoding\n",
    "print(\"Performing one-hot encoding...\")\n",
    "data_bin_hot = pd.get_dummies(data_bin, columns=cols_cat)\n",
    "print(f\"Shape after encoding: {data_bin_hot.shape}\")\n",
    "\n",
    "# Normalization\n",
    "cols_numeric = list(cols_numeric)\n",
    "cols_numeric.remove('label')\n",
    "cols_numeric.remove('id')\n",
    "data_bin_hot[cols_numeric] = data_bin_hot[cols_numeric].astype('float')\n",
    "data_bin_hot[cols_numeric] = (data_bin_hot[cols_numeric] - np.min(data_bin_hot[cols_numeric])) / np.std(data_bin_hot[cols_numeric])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e72650-bcfa-4c94-8c9b-5d7d17868249",
   "metadata": {},
   "source": [
    "## Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cef9915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:09.792686Z",
     "iopub.status.busy": "2025-12-03T17:54:09.792508Z",
     "iopub.status.idle": "2025-12-03T17:54:09.824317Z",
     "shell.execute_reply": "2025-12-03T17:54:09.823673Z",
     "shell.execute_reply.started": "2025-12-03T17:54:09.792671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (257673, 196)\n",
      "Labels shape: (257673,)\n",
      "Attack samples: 164673 (63.91%)\n",
      "Normal samples: 93000 (36.09%)\n"
     ]
    }
   ],
   "source": [
    "X = data_bin_hot.drop('label', axis=1)\n",
    "Y = data_bin_hot['label'].astype(int)  # Convert to integer!\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {Y.shape}\")\n",
    "print(f\"Attack samples: {Y.sum()} ({Y.sum()/len(Y)*100:.2f}%)\")\n",
    "print(f\"Normal samples: {len(Y)-Y.sum()} ({(len(Y)-Y.sum())/len(Y)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cfc70-0728-4bc4-870c-c47cc9bb22e0",
   "metadata": {},
   "source": [
    "## Enhanced Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4095a71f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:09.825016Z",
     "iopub.status.busy": "2025-12-03T17:54:09.824887Z",
     "iopub.status.idle": "2025-12-03T17:54:09.835169Z",
     "shell.execute_reply": "2025-12-03T17:54:09.834584Z",
     "shell.execute_reply.started": "2025-12-03T17:54:09.825002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "def get_model_size_mb(model):\n",
    "    \"\"\"Calculate model size in MB\"\"\"\n",
    "    model_bytes = pickle.dumps(model)\n",
    "    return len(model_bytes) / (1024 * 1024)\n",
    "\n",
    "def fit_algo_comprehensive(algo, x, y, cv=10, algo_name=\"Algorithm\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with cloud-deployment metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {algo_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Get baseline resource usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    baseline_memory = process.memory_info().rss / (1024 * 1024)\n",
    "    \n",
    "    # TRAINING PHASE\n",
    "    print(\"Training model...\")\n",
    "    train_start = time.time()\n",
    "    \n",
    "    def train_with_monitoring():\n",
    "        model = algo.fit(x, y)\n",
    "        return model\n",
    "    \n",
    "    mem_usage = memory_usage((train_with_monitoring,), interval=0.1, timeout=None)\n",
    "    model = algo.fit(x, y)\n",
    "    \n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    \n",
    "    peak_memory = max(mem_usage)\n",
    "    memory_used = peak_memory - baseline_memory\n",
    "    \n",
    "    results['training_time_sec'] = round(train_time, 3)\n",
    "    results['memory_mb'] = round(memory_used, 2)\n",
    "    \n",
    "    # PREDICTION PHASE\n",
    "    print(\"Making predictions...\")\n",
    "    predict_start = time.time()\n",
    "    y_pred = model.predict(x)\n",
    "    predict_end = time.time()\n",
    "    \n",
    "    prediction_time = predict_end - predict_start\n",
    "    avg_prediction_latency = (prediction_time / len(x)) * 1000\n",
    "    \n",
    "    results['prediction_time_sec'] = round(prediction_time, 3)\n",
    "    results['avg_latency_ms'] = round(avg_prediction_latency, 4)\n",
    "    \n",
    "    # CROSS-VALIDATION PREDICTIONS\n",
    "    print(\"Performing cross-validation...\")\n",
    "    cv_start = time.time()\n",
    "    y_pred_cv = model_selection.cross_val_predict(algo, x, y, cv=cv, n_jobs=-1)\n",
    "    cv_end = time.time()\n",
    "    \n",
    "    results['cv_time_sec'] = round(cv_end - cv_start, 3)\n",
    "    \n",
    "    # PERFORMANCE METRICS\n",
    "    results['accuracy_train'] = round(metrics.accuracy_score(y, y_pred) * 100, 2)\n",
    "    results['precision_train'] = round(metrics.precision_score(y, y_pred, zero_division=0) * 100, 2)\n",
    "    results['recall_train'] = round(metrics.recall_score(y, y_pred, zero_division=0) * 100, 2)\n",
    "    results['f1_train'] = round(metrics.f1_score(y, y_pred, zero_division=0) * 100, 2)\n",
    "    \n",
    "    results['accuracy_cv'] = round(metrics.accuracy_score(y, y_pred_cv) * 100, 2)\n",
    "    results['precision_cv'] = round(metrics.precision_score(y, y_pred_cv, zero_division=0) * 100, 2)\n",
    "    results['recall_cv'] = round(metrics.recall_score(y, y_pred_cv, zero_division=0) * 100, 2)\n",
    "    results['f1_cv'] = round(metrics.f1_score(y, y_pred_cv, zero_division=0) * 100, 2)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = metrics.confusion_matrix(y, y_pred_cv)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    results['confusion_matrix'] = cm\n",
    "    results['tn'] = int(tn)\n",
    "    results['fp'] = int(fp)\n",
    "    results['fn'] = int(fn)\n",
    "    results['tp'] = int(tp)\n",
    "    \n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    results['fpr'] = round(fpr * 100, 2)\n",
    "    \n",
    "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    results['tnr'] = round(tnr * 100, 2)\n",
    "    \n",
    "    # MODEL SIZE\n",
    "    model_size = get_model_size_mb(model)\n",
    "    results['model_size_mb'] = round(model_size, 2)\n",
    "    \n",
    "    # CLOUD-DEPLOYMENT METRICS\n",
    "    throughput = len(x) / prediction_time\n",
    "    results['throughput_samples_per_sec'] = round(throughput, 2)\n",
    "    \n",
    "    cost_effectiveness = results['f1_cv'] / train_time if train_time > 0 else 0\n",
    "    results['cost_effectiveness'] = round(cost_effectiveness, 2)\n",
    "    \n",
    "    perf_per_mb = results['f1_cv'] / memory_used if memory_used > 0 else 0\n",
    "    results['performance_per_mb'] = round(perf_per_mb, 2)\n",
    "    \n",
    "    scalability_score = (throughput / 1000) / (avg_prediction_latency if avg_prediction_latency > 0 else 1)\n",
    "    results['scalability_score'] = round(scalability_score, 4)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'Results Summary':^60}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"{'PERFORMANCE METRICS (Cross-Validation)':^60}\")\n",
    "    print(f\"  Accuracy:        {results['accuracy_cv']:>6.2f}%\")\n",
    "    print(f\"  Precision:       {results['precision_cv']:>6.2f}%\")\n",
    "    print(f\"  Recall:          {results['recall_cv']:>6.2f}%\")\n",
    "    print(f\"  F1-Score:        {results['f1_cv']:>6.2f}%\")\n",
    "    print(f\"  False Pos. Rate: {results['fpr']:>6.2f}%\")\n",
    "    print(f\"\\n{'CONFUSION MATRIX':^60}\")\n",
    "    print(f\"  True Negatives:  {results['tn']:>10,}\")\n",
    "    print(f\"  False Positives: {results['fp']:>10,}\")\n",
    "    print(f\"  False Negatives: {results['fn']:>10,}\")\n",
    "    print(f\"  True Positives:  {results['tp']:>10,}\")\n",
    "    print(f\"\\n{'RESOURCE METRICS':^60}\")\n",
    "    print(f\"  Training Time:   {results['training_time_sec']:>8.3f} sec\")\n",
    "    print(f\"  Prediction Time: {results['prediction_time_sec']:>8.3f} sec\")\n",
    "    print(f\"  Avg Latency:     {results['avg_latency_ms']:>8.4f} ms/sample\")\n",
    "    print(f\"  Memory Used:     {results['memory_mb']:>8.2f} MB\")\n",
    "    print(f\"  Model Size:      {results['model_size_mb']:>8.2f} MB\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return y_pred_cv, results, model\n",
    "\n",
    "print(\"✅ Evaluation function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113db49-3f09-434f-9aa3-4fc7398ea19e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Baseline Model Evaluations\n",
    "First, we'll evaluate models with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa29ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:54:09.835828Z",
     "iopub.status.busy": "2025-12-03T17:54:09.835588Z",
     "iopub.status.idle": "2025-12-03T17:58:24.144373Z",
     "shell.execute_reply": "2025-12-03T17:58:24.143679Z",
     "shell.execute_reply.started": "2025-12-03T17:54:09.835813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE: LOGISTIC REGRESSION (Default Parameters)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "Evaluating: Logistic Regression (Default)\n",
      "============================================================\n",
      "Training model...\n",
      "Making predictions...\n",
      "Performing cross-validation...\n",
      "\n",
      "                      Results Summary                       \n",
      "------------------------------------------------------------\n",
      "           PERFORMANCE METRICS (Cross-Validation)           \n",
      "  Accuracy:         89.24%\n",
      "  Precision:        88.13%\n",
      "  Recall:           96.11%\n",
      "  F1-Score:         91.95%\n",
      "  False Pos. Rate:  22.93%\n",
      "\n",
      "                      CONFUSION MATRIX                      \n",
      "  True Negatives:      71,674\n",
      "  False Positives:     21,326\n",
      "  False Negatives:      6,398\n",
      "  True Positives:     158,275\n",
      "\n",
      "                      RESOURCE METRICS                      \n",
      "  Training Time:     34.490 sec\n",
      "  Prediction Time:    0.152 sec\n",
      "  Avg Latency:       0.0006 ms/sample\n",
      "  Memory Used:       586.67 MB\n",
      "  Model Size:          0.00 MB\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression (Default)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE: LOGISTIC REGRESSION (Default Parameters)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lr_algo = LogisticRegression(max_iter=1000, random_state=42)\n",
    "y_pred_lr, results_lr, model_lr = fit_algo_comprehensive(lr_algo, X, Y, cv=10, algo_name=\"Logistic Regression (Default)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95bc7f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T17:58:24.145264Z",
     "iopub.status.busy": "2025-12-03T17:58:24.145111Z",
     "iopub.status.idle": "2025-12-03T18:03:43.238818Z",
     "shell.execute_reply": "2025-12-03T18:03:43.238204Z",
     "shell.execute_reply.started": "2025-12-03T17:58:24.145248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE: K-NEAREST NEIGHBORS (Default Parameters)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "Evaluating: KNN (Default)\n",
      "============================================================\n",
      "Training model...\n",
      "Making predictions...\n",
      "Performing cross-validation...\n",
      "\n",
      "                      Results Summary                       \n",
      "------------------------------------------------------------\n",
      "           PERFORMANCE METRICS (Cross-Validation)           \n",
      "  Accuracy:         88.69%\n",
      "  Precision:        90.30%\n",
      "  Recall:           92.21%\n",
      "  F1-Score:         91.24%\n",
      "  False Pos. Rate:  17.54%\n",
      "\n",
      "                      CONFUSION MATRIX                      \n",
      "  True Negatives:      76,691\n",
      "  False Positives:     16,309\n",
      "  False Negatives:     12,836\n",
      "  True Positives:     151,837\n",
      "\n",
      "                      RESOURCE METRICS                      \n",
      "  Training Time:      0.513 sec\n",
      "  Prediction Time:  158.012 sec\n",
      "  Avg Latency:       0.6132 ms/sample\n",
      "  Memory Used:       956.00 MB\n",
      "  Model Size:        387.28 MB\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. K-Nearest Neighbors (Default)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE: K-NEAREST NEIGHBORS (Default Parameters)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "knn_algo = KNeighborsClassifier(n_jobs=-1)\n",
    "y_pred_knn, results_knn, model_knn = fit_algo_comprehensive(knn_algo, X, Y, cv=5, algo_name=\"KNN (Default)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182461d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:03:43.239540Z",
     "iopub.status.busy": "2025-12-03T18:03:43.239397Z",
     "iopub.status.idle": "2025-12-03T18:05:14.005564Z",
     "shell.execute_reply": "2025-12-03T18:05:14.004944Z",
     "shell.execute_reply.started": "2025-12-03T18:03:43.239524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE: LINEAR SVC (Default Parameters)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "Evaluating: Linear SVC (Default)\n",
      "============================================================\n",
      "Training model...\n",
      "Making predictions...\n",
      "Performing cross-validation...\n",
      "\n",
      "                      Results Summary                       \n",
      "------------------------------------------------------------\n",
      "           PERFORMANCE METRICS (Cross-Validation)           \n",
      "  Accuracy:         88.26%\n",
      "  Precision:        86.70%\n",
      "  Recall:           96.42%\n",
      "  F1-Score:         91.30%\n",
      "  False Pos. Rate:  26.20%\n",
      "\n",
      "                      CONFUSION MATRIX                      \n",
      "  True Negatives:      68,634\n",
      "  False Positives:     24,366\n",
      "  False Negatives:      5,894\n",
      "  True Positives:     158,779\n",
      "\n",
      "                      RESOURCE METRICS                      \n",
      "  Training Time:     54.805 sec\n",
      "  Prediction Time:    0.135 sec\n",
      "  Avg Latency:       0.0005 ms/sample\n",
      "  Memory Used:      1078.26 MB\n",
      "  Model Size:          0.00 MB\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Linear SVC (Default)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE: LINEAR SVC (Default Parameters)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "svc_algo = LinearSVC(max_iter=1000, random_state=42)\n",
    "y_pred_svc, results_svc, model_svc = fit_algo_comprehensive(svc_algo, X, Y, cv=5, algo_name=\"Linear SVC (Default)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb9597-45b3-44d8-b36d-10bb989f0c45",
   "metadata": {},
   "source": [
    "## GRID SEARCH HYPERPARAMETER TUNING\n",
    "Now we'll optimize these three algorithms using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172a850-c450-4d4e-b37c-e26dbbe69849",
   "metadata": {},
   "source": [
    "### Grid Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b3d20ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:05:14.007380Z",
     "iopub.status.busy": "2025-12-03T18:05:14.007186Z",
     "iopub.status.idle": "2025-12-03T18:05:14.013063Z",
     "shell.execute_reply": "2025-12-03T18:05:14.012458Z",
     "shell.execute_reply.started": "2025-12-03T18:05:14.007360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grid search function defined with memory optimization\n"
     ]
    }
   ],
   "source": [
    "def grid_search_optimize(base_model, param_grid, X, y, cv=5, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Perform grid search to find optimal hyperparameters\n",
    "    \n",
    "    Args:\n",
    "        base_model: Base sklearn model\n",
    "        param_grid: Dictionary of parameters to search\n",
    "        X, y: Training data\n",
    "        cv: Cross-validation folds\n",
    "        model_name: Name for display\n",
    "    \n",
    "    Returns:\n",
    "        best_model, best_params, best_score, grid_search_results\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"GRID SEARCH: {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Parameter grid: {param_grid}\")\n",
    "    print(f\"Cross-validation folds: {cv}\")\n",
    "    print(f\"Scoring metric: F1-Score\\n\")\n",
    "    \n",
    "    print(\"Starting grid search... (this may take a while)\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create grid search object with reduced n_jobs to prevent memory overload\n",
    "    # Use n_jobs=3 or n_jobs=4 instead of -1 (all cores)\n",
    "    n_jobs = min(4, os.cpu_count() // 2)  # Use half available cores max\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Force garbage collection after grid search\n",
    "    gc.collect()\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"GRID SEARCH COMPLETE - {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Search time: {search_time:.2f} seconds\")\n",
    "    print(f\"\\nBest Parameters:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"\\nBest Cross-Validation F1-Score: {grid_search.best_score_*100:.2f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Get results dataframe\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_, results_df\n",
    "\n",
    "print(\"✅ Grid search function defined with memory optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7fee4-621d-48f7-8ea6-0ab360b37990",
   "metadata": {},
   "source": [
    "### Grid Search: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea08046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:05:14.013665Z",
     "iopub.status.busy": "2025-12-03T18:05:14.013511Z",
     "iopub.status.idle": "2025-12-03T20:11:58.306065Z",
     "shell.execute_reply": "2025-12-03T20:11:58.303782Z",
     "shell.execute_reply.started": "2025-12-03T18:05:14.013649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING: LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GRID SEARCH: Logistic Regression\n",
      "======================================================================\n",
      "Parameter grid: {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga'], 'max_iter': [1000]}\n",
      "Cross-validation folds: 5\n",
      "Scoring metric: F1-Score\n",
      "\n",
      "Starting grid search... (this may take a while)\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "======================================================================\n",
      "GRID SEARCH COMPLETE - Logistic Regression\n",
      "======================================================================\n",
      "Search time: 7309.36 seconds\n",
      "\n",
      "Best Parameters:\n",
      "  C: 100\n",
      "  max_iter: 1000\n",
      "  penalty: l2\n",
      "  solver: liblinear\n",
      "\n",
      "Best Cross-Validation F1-Score: 91.89%\n",
      "======================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Evaluating: Logistic Regression (Tuned)\n",
      "============================================================\n",
      "Training model...\n",
      "Making predictions...\n",
      "Performing cross-validation...\n",
      "\n",
      "                      Results Summary                       \n",
      "------------------------------------------------------------\n",
      "           PERFORMANCE METRICS (Cross-Validation)           \n",
      "  Accuracy:         89.48%\n",
      "  Precision:        88.43%\n",
      "  Recall:           96.12%\n",
      "  F1-Score:         92.11%\n",
      "  False Pos. Rate:  22.27%\n",
      "\n",
      "                      CONFUSION MATRIX                      \n",
      "  True Negatives:      72,292\n",
      "  False Positives:     20,708\n",
      "  False Negatives:      6,393\n",
      "  True Positives:     158,280\n",
      "\n",
      "                      RESOURCE METRICS                      \n",
      "  Training Time:     59.367 sec\n",
      "  Prediction Time:    0.140 sec\n",
      "  Avg Latency:       0.0005 ms/sample\n",
      "  Memory Used:       998.30 MB\n",
      "  Model Size:          0.00 MB\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define parameter grid\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "lr_best_model, lr_best_params, lr_best_score, lr_grid_results = grid_search_optimize(\n",
    "    base_model=LogisticRegression(random_state=42),\n",
    "    param_grid=lr_param_grid,\n",
    "    X=X,\n",
    "    y=Y,\n",
    "    cv=5,\n",
    "    model_name=\"Logistic Regression\"\n",
    ")\n",
    "\n",
    "# Evaluate best model comprehensively\n",
    "y_pred_lr_tuned, results_lr_tuned, model_lr_tuned = fit_algo_comprehensive(\n",
    "    lr_best_model, X, Y, cv=10, algo_name=\"Logistic Regression (Tuned)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f61ac-34cd-4b38-8062-8f616a420dd0",
   "metadata": {},
   "source": [
    "### Grid Search Results Analysis: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298e17d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T20:11:58.307737Z",
     "iopub.status.busy": "2025-12-03T20:11:58.307423Z",
     "iopub.status.idle": "2025-12-03T20:11:58.319702Z",
     "shell.execute_reply": "2025-12-03T20:11:58.319238Z",
     "shell.execute_reply.started": "2025-12-03T20:11:58.307709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Configurations (Logistic Regression):\n",
      "======================================================================\n",
      "                                                            Parameters  F1-Score (%)  Std Dev (%)  Fit Time (s)\n",
      "  {'C': 100, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}     91.887553     6.152008     33.301567\n",
      "{'C': 0.001, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}     91.842851     7.198336      4.319365\n",
      "   {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}     91.838522     6.196889     27.134698\n",
      "    {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}     91.795439     6.248639    176.163268\n",
      "  {'C': 100, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}     91.786605     6.246021    258.035637\n",
      "   {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}     91.784282     6.245152    173.631442\n",
      "  {'C': 0.1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}     91.778978     6.372170     56.667078\n",
      "    {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}     91.775805     6.316596     12.765403\n",
      "        {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}     91.747857     6.431044    487.227335\n",
      "       {'C': 100, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}     91.747443     6.430404    432.514727\n",
      "\n",
      "======================================================================\n",
      "IMPROVEMENT ANALYSIS: Logistic Regression\n",
      "======================================================================\n",
      "Default F1-Score:  91.95%\n",
      "Tuned F1-Score:    92.11%\n",
      "Improvement:       +0.16%\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show top 10 configurations\n",
    "print(\"\\nTop 10 Configurations (Logistic Regression):\")\n",
    "print(\"=\"*70)\n",
    "lr_top10 = lr_grid_results.nlargest(10, 'mean_test_score')[\n",
    "    ['params', 'mean_test_score', 'std_test_score', 'mean_fit_time']\n",
    "]\n",
    "lr_top10['mean_test_score'] = lr_top10['mean_test_score'] * 100\n",
    "lr_top10['std_test_score'] = lr_top10['std_test_score'] * 100\n",
    "lr_top10.columns = ['Parameters', 'F1-Score (%)', 'Std Dev (%)', 'Fit Time (s)']\n",
    "print(lr_top10.to_string(index=False))\n",
    "\n",
    "# Improvement analysis\n",
    "improvement_lr = results_lr_tuned['f1_cv'] - results_lr['f1_cv']\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"IMPROVEMENT ANALYSIS: Logistic Regression\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Default F1-Score:  {results_lr['f1_cv']:.2f}%\")\n",
    "print(f\"Tuned F1-Score:    {results_lr_tuned['f1_cv']:.2f}%\")\n",
    "print(f\"Improvement:       {improvement_lr:+.2f}%\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c7bac-2baf-4d52-9c41-3b067ab61002",
   "metadata": {},
   "source": [
    "### Grid Search: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4bd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING: K-NEAREST NEIGHBORS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define parameter grid\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]  # Power parameter for Minkowski\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "knn_best_model, knn_best_params, knn_best_score, knn_grid_results = grid_search_optimize(\n",
    "    base_model=KNeighborsClassifier(n_jobs=-1),\n",
    "    param_grid=knn_param_grid,\n",
    "    X=X,\n",
    "    y=Y,\n",
    "    cv=3,  # Reduced CV for KNN (slower)\n",
    "    model_name=\"K-Nearest Neighbors\"\n",
    ")\n",
    "\n",
    "# Evaluate best model comprehensively\n",
    "y_pred_knn_tuned, results_knn_tuned, model_knn_tuned = fit_algo_comprehensive(\n",
    "    knn_best_model, X, Y, cv=5, algo_name=\"KNN (Tuned)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfffd91-fbce-4371-9b7c-714ca3770848",
   "metadata": {},
   "source": [
    "### Grid Search Results Analysis: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 configurations\n",
    "print(\"\\nTop 10 Configurations (KNN):\")\n",
    "print(\"=\"*70)\n",
    "knn_top10 = knn_grid_results.nlargest(10, 'mean_test_score')[\n",
    "    ['params', 'mean_test_score', 'std_test_score', 'mean_fit_time']\n",
    "]\n",
    "knn_top10['mean_test_score'] = knn_top10['mean_test_score'] * 100\n",
    "knn_top10['std_test_score'] = knn_top10['std_test_score'] * 100\n",
    "knn_top10.columns = ['Parameters', 'F1-Score (%)', 'Std Dev (%)', 'Fit Time (s)']\n",
    "print(knn_top10.to_string(index=False))\n",
    "\n",
    "# Improvement analysis\n",
    "improvement_knn = results_knn_tuned['f1_cv'] - results_knn['f1_cv']\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"IMPROVEMENT ANALYSIS: K-Nearest Neighbors\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Default F1-Score:  {results_knn['f1_cv']:.2f}%\")\n",
    "print(f\"Tuned F1-Score:    {results_knn_tuned['f1_cv']:.2f}%\")\n",
    "print(f\"Improvement:       {improvement_knn:+.2f}%\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaac0f1-7f29-4e02-82c4-9743b719d260",
   "metadata": {},
   "source": [
    "### Grid Search: Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f53750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING: LINEAR SVC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define parameter grid\n",
    "svc_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],  # LinearSVC only supports l2\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "svc_best_model, svc_best_params, svc_best_score, svc_grid_results = grid_search_optimize(\n",
    "    base_model=LinearSVC(random_state=42),\n",
    "    param_grid=svc_param_grid,\n",
    "    X=X,\n",
    "    y=Y,\n",
    "    cv=5,\n",
    "    model_name=\"Linear SVC\"\n",
    ")\n",
    "\n",
    "# Evaluate best model comprehensively\n",
    "y_pred_svc_tuned, results_svc_tuned, model_svc_tuned = fit_algo_comprehensive(\n",
    "    svc_best_model, X, Y, cv=5, algo_name=\"Linear SVC (Tuned)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2327c0e-da86-48de-bef4-9dcdcf443992",
   "metadata": {},
   "source": [
    "### Grid Search Results Analysis: Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7be60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 configurations\n",
    "print(\"\\nTop 10 Configurations (Linear SVC):\")\n",
    "print(\"=\"*70)\n",
    "svc_top10 = svc_grid_results.nlargest(10, 'mean_test_score')[\n",
    "    ['params', 'mean_test_score', 'std_test_score', 'mean_fit_time']\n",
    "]\n",
    "svc_top10['mean_test_score'] = svc_top10['mean_test_score'] * 100\n",
    "svc_top10['std_test_score'] = svc_top10['std_test_score'] * 100\n",
    "svc_top10.columns = ['Parameters', 'F1-Score (%)', 'Std Dev (%)', 'Fit Time (s)']\n",
    "print(svc_top10.to_string(index=False))\n",
    "\n",
    "# Improvement analysis\n",
    "improvement_svc = results_svc_tuned['f1_cv'] - results_svc['f1_cv']\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"IMPROVEMENT ANALYSIS: Linear SVC\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Default F1-Score:  {results_svc['f1_cv']:.2f}%\")\n",
    "print(f\"Tuned F1-Score:    {results_svc_tuned['f1_cv']:.2f}%\")\n",
    "print(f\"Improvement:       {improvement_svc:+.2f}%\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13b1d5-3824-4957-b6eb-9c362d852ee3",
   "metadata": {},
   "source": [
    "## Additional Baseline Models\n",
    "Evaluate other algorithms with default parameters for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c5e44-64d6-47c9-ad39-70826f62c5d3",
   "metadata": {},
   "source": [
    "### 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALGORITHM 4: DECISION TREE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "dt_algo = DecisionTreeClassifier(random_state=42)\n",
    "y_pred_dt, results_dt, model_dt = fit_algo_comprehensive(dt_algo, X, Y, cv=10, algo_name=\"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caaa0b2-9abd-4148-9ebb-926bac11b2f0",
   "metadata": {},
   "source": [
    "### 5. Random Forest (Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc824620",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALGORITHM 5: RANDOM FOREST (GINI)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf_algo = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42, n_jobs=-1)\n",
    "y_pred_rf, results_rf, model_rf = fit_algo_comprehensive(rf_algo, X, Y, cv=10, algo_name=\"Random Forest (Gini)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0a9b8-d860-4e9b-ad02-dffe37b2a80d",
   "metadata": {},
   "source": [
    "### 6. Random Forest (Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59856a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALGORITHM 6: RANDOM FOREST (ENTROPY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf2_algo = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42, n_jobs=-1)\n",
    "y_pred_rf2, results_rf2, model_rf2 = fit_algo_comprehensive(rf2_algo, X, Y, cv=10, algo_name=\"Random Forest (Entropy)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75a6db-c63e-45c8-a955-029a0f1b7d89",
   "metadata": {},
   "source": [
    "### 7. Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALGORITHM 7: MULTI-LAYER PERCEPTRON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mlp_algo = MLPClassifier(hidden_layer_sizes=(20,), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
    "y_pred_mlp, results_mlp, model_mlp = fit_algo_comprehensive(mlp_algo, X, Y, cv=5, algo_name=\"Multi-Layer Perceptron\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e15546-730b-4785-a784-cce5cf2ac70e",
   "metadata": {},
   "source": [
    "### Comprehensive Comparison: Default vs Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91930bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_results = {\n",
    "    'Logistic Regression (Default)': results_lr,\n",
    "    'Logistic Regression (Tuned)': results_lr_tuned,\n",
    "    'KNN (Default)': results_knn,\n",
    "    'KNN (Tuned)': results_knn_tuned,\n",
    "    'Linear SVC (Default)': results_svc,\n",
    "    'Linear SVC (Tuned)': results_svc_tuned,\n",
    "    'Decision Tree': results_dt,\n",
    "    'Random Forest (Gini)': results_rf,\n",
    "    'Random Forest (Entropy)': results_rf2,\n",
    "    'Multi-Layer Perceptron': results_mlp\n",
    "}\n",
    "\n",
    "# Create comprehensive comparison DataFrame\n",
    "comparison_df = pd.DataFrame(all_results).T\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE ALGORITHM COMPARISON (Including Tuned Models)\")\n",
    "print(\"=\"*100)\n",
    "print(comparison_df[['accuracy_cv', 'precision_cv', 'recall_cv', 'f1_cv', 'fpr', \n",
    "                      'training_time_sec', 'avg_latency_ms']].to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ff9a7-7c34-4175-89f4-b095d4354398",
   "metadata": {},
   "source": [
    "### Performance Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_cols = ['accuracy_cv', 'precision_cv', 'recall_cv', 'f1_cv', 'fpr']\n",
    "perf_df = comparison_df[perf_cols].copy()\n",
    "perf_df.columns = ['Accuracy (%)', 'Precision (%)', 'Recall (%)', 'F1-Score (%)', 'FPR (%)']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE METRICS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(perf_df.to_string())\n",
    "\n",
    "# Sort by F1-Score\n",
    "perf_df_sorted = perf_df.sort_values('F1-Score (%)', ascending=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKED BY F1-SCORE\")\n",
    "print(\"=\"*80)\n",
    "print(perf_df_sorted.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7482b6-a579-40f0-918c-17c79c78cebd",
   "metadata": {},
   "source": [
    "### Tuning Improvement Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f525ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING IMPACT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "improvements = pd.DataFrame([\n",
    "    {\n",
    "        'Algorithm': 'Logistic Regression',\n",
    "        'Default F1 (%)': results_lr['f1_cv'],\n",
    "        'Tuned F1 (%)': results_lr_tuned['f1_cv'],\n",
    "        'Improvement (%)': results_lr_tuned['f1_cv'] - results_lr['f1_cv'],\n",
    "        'Best Parameters': str(lr_best_params)\n",
    "    },\n",
    "    {\n",
    "        'Algorithm': 'K-Nearest Neighbors',\n",
    "        'Default F1 (%)': results_knn['f1_cv'],\n",
    "        'Tuned F1 (%)': results_knn_tuned['f1_cv'],\n",
    "        'Improvement (%)': results_knn_tuned['f1_cv'] - results_knn['f1_cv'],\n",
    "        'Best Parameters': str(knn_best_params)\n",
    "    },\n",
    "    {\n",
    "        'Algorithm': 'Linear SVC',\n",
    "        'Default F1 (%)': results_svc['f1_cv'],\n",
    "        'Tuned F1 (%)': results_svc_tuned['f1_cv'],\n",
    "        'Improvement (%)': results_svc_tuned['f1_cv'] - results_svc['f1_cv'],\n",
    "        'Best Parameters': str(svc_best_params)\n",
    "    }\n",
    "])\n",
    "\n",
    "print(improvements[['Algorithm', 'Default F1 (%)', 'Tuned F1 (%)', 'Improvement (%)']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BEST HYPERPARAMETERS\")\n",
    "print(f\"{'='*80}\")\n",
    "for _, row in improvements.iterrows():\n",
    "    print(f\"\\n{row['Algorithm']}:\")\n",
    "    print(f\"  {row['Best Parameters']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246341d-039a-4c4d-affc-281454f20062",
   "metadata": {},
   "source": [
    "## Confusion Matrices Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70858794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title, ax):\n",
    "    \"\"\"Plot confusion matrix heatmap\"\"\"\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Normal', 'Attack'],\n",
    "                yticklabels=['Normal', 'Attack'])\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label', fontsize=10)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=10)\n",
    "    \n",
    "    # Add accuracy to title\n",
    "    accuracy = (cm[0,0] + cm[1,1]) / cm.sum() * 100\n",
    "    ax.text(0.5, -0.15, f'Accuracy: {accuracy:.2f}%', \n",
    "            ha='center', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "# Plot confusion matrices for tuned models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Tuned models\n",
    "plot_confusion_matrix(results_lr_tuned['confusion_matrix'], \n",
    "                     'Logistic Regression (Tuned)', axes[0, 0])\n",
    "plot_confusion_matrix(results_knn_tuned['confusion_matrix'], \n",
    "                     'KNN (Tuned)', axes[0, 1])\n",
    "plot_confusion_matrix(results_svc_tuned['confusion_matrix'], \n",
    "                     'Linear SVC (Tuned)', axes[0, 2])\n",
    "\n",
    "# Best other models\n",
    "plot_confusion_matrix(results_rf2['confusion_matrix'], \n",
    "                     'Random Forest (Entropy)', axes[1, 0])\n",
    "plot_confusion_matrix(results_rf['confusion_matrix'], \n",
    "                     'Random Forest (Gini)', axes[1, 1])\n",
    "plot_confusion_matrix(results_mlp['confusion_matrix'], \n",
    "                     'Multi-Layer Perceptron', axes[1, 2])\n",
    "\n",
    "plt.suptitle('Confusion Matrices: Best Performing Models', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices_all_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Confusion matrices saved as 'confusion_matrices_all_models.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0b23e-450b-42ab-a77c-e9d2d8758faa",
   "metadata": {},
   "source": [
    "## Comparison: Default vs Tuned (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e254491",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Prepare data\n",
    "algorithms = ['Logistic\\nRegression', 'K-Nearest\\nNeighbors', 'Linear\\nSVC']\n",
    "default_f1 = [results_lr['f1_cv'], results_knn['f1_cv'], results_svc['f1_cv']]\n",
    "tuned_f1 = [results_lr_tuned['f1_cv'], results_knn_tuned['f1_cv'], results_svc_tuned['f1_cv']]\n",
    "\n",
    "x = np.arange(len(algorithms))\n",
    "width = 0.35\n",
    "\n",
    "# Plot 1: F1-Score Comparison\n",
    "ax = axes[0]\n",
    "bars1 = ax.bar(x - width/2, default_f1, width, label='Default', color='steelblue', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, tuned_f1, width, label='Tuned', color='coral', alpha=0.7)\n",
    "ax.set_ylabel('F1-Score (%)', fontsize=11)\n",
    "ax.set_title('F1-Score: Default vs Tuned', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithms)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Improvement\n",
    "improvements_list = [\n",
    "    results_lr_tuned['f1_cv'] - results_lr['f1_cv'],\n",
    "    results_knn_tuned['f1_cv'] - results_knn['f1_cv'],\n",
    "    results_svc_tuned['f1_cv'] - results_svc['f1_cv']\n",
    "]\n",
    "ax = axes[1]\n",
    "colors = ['green' if x > 0 else 'red' for x in improvements_list]\n",
    "bars = ax.bar(algorithms, improvements_list, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('F1-Score Improvement (%)', fontsize=11)\n",
    "ax.set_title('Improvement from Hyperparameter Tuning', fontsize=12, fontweight='bold')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:+.2f}', ha='center', va='bottom' if height > 0 else 'top', fontsize=10)\n",
    "\n",
    "# Plot 3: Training Time Comparison\n",
    "default_times = [results_lr['training_time_sec'], results_knn['training_time_sec'], results_svc['training_time_sec']]\n",
    "tuned_times = [results_lr_tuned['training_time_sec'], results_knn_tuned['training_time_sec'], results_svc_tuned['training_time_sec']]\n",
    "\n",
    "ax = axes[2]\n",
    "bars1 = ax.bar(x - width/2, default_times, width, label='Default', color='steelblue', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, tuned_times, width, label='Tuned', color='coral', alpha=0.7)\n",
    "ax.set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "ax.set_title('Training Time: Default vs Tuned', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithms)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Hyperparameter Tuning Impact Analysis', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('tuning_impact_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Tuning comparison saved as 'tuning_impact_comparison.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6fb487-6374-4c52-a495-7ce9cc9396ad",
   "metadata": {},
   "source": [
    "## Performance Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Accuracy\n",
    "perf_df_sorted_acc = perf_df.sort_values('Accuracy (%)')\n",
    "ax = axes[0, 0]\n",
    "colors = ['coral' if 'Tuned' in idx else 'steelblue' for idx in perf_df_sorted_acc.index]\n",
    "perf_df_sorted_acc['Accuracy (%)'].plot(kind='barh', ax=ax, color=colors, alpha=0.7)\n",
    "ax.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Accuracy (%)')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.legend(['Default', 'Tuned'], loc='lower right')\n",
    "\n",
    "# Plot 2: F1-Score\n",
    "perf_df_sorted_f1 = perf_df.sort_values('F1-Score (%)')\n",
    "ax = axes[0, 1]\n",
    "colors = ['coral' if 'Tuned' in idx else 'steelblue' for idx in perf_df_sorted_f1.index]\n",
    "perf_df_sorted_f1['F1-Score (%)'].plot(kind='barh', ax=ax, color=colors, alpha=0.7)\n",
    "ax.set_title('F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('F1-Score (%)')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 3: Precision\n",
    "perf_df_sorted_prec = perf_df.sort_values('Precision (%)')\n",
    "ax = axes[1, 0]\n",
    "colors = ['coral' if 'Tuned' in idx else 'steelblue' for idx in perf_df_sorted_prec.index]\n",
    "perf_df_sorted_prec['Precision (%)'].plot(kind='barh', ax=ax, color=colors, alpha=0.7)\n",
    "ax.set_title('Precision Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Precision (%)')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 4: Recall\n",
    "perf_df_sorted_rec = perf_df.sort_values('Recall (%)')\n",
    "ax = axes[1, 1]\n",
    "colors = ['coral' if 'Tuned' in idx else 'steelblue' for idx in perf_df_sorted_rec.index]\n",
    "perf_df_sorted_rec['Recall (%)'].plot(kind='barh', ax=ax, color=colors, alpha=0.7)\n",
    "ax.set_title('Recall Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Recall (%)')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Performance Metrics Comparison (Tuned models highlighted in coral)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_metrics_with_tuning.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Performance metrics saved as 'performance_metrics_with_tuning.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9619f-37e4-4460-9ab5-851cda45163f",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c412478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive results\n",
    "comparison_df.to_csv('ml_algorithms_comprehensive_with_tuning.csv')\n",
    "print(\"✅ Saved: ml_algorithms_comprehensive_with_tuning.csv\")\n",
    "\n",
    "# Export performance metrics\n",
    "perf_df.to_csv('performance_metrics_with_tuning.csv')\n",
    "print(\"✅ Saved: performance_metrics_with_tuning.csv\")\n",
    "\n",
    "# Export tuning results\n",
    "improvements.to_csv('hyperparameter_tuning_improvements.csv', index=False)\n",
    "print(\"✅ Saved: hyperparameter_tuning_improvements.csv\")\n",
    "\n",
    "# Export best parameters\n",
    "best_params_df = pd.DataFrame([\n",
    "    {'Algorithm': 'Logistic Regression', 'Best Parameters': str(lr_best_params)},\n",
    "    {'Algorithm': 'K-Nearest Neighbors', 'Best Parameters': str(knn_best_params)},\n",
    "    {'Algorithm': 'Linear SVC', 'Best Parameters': str(svc_best_params)}\n",
    "])\n",
    "best_params_df.to_csv('best_hyperparameters.csv', index=False)\n",
    "print(\"✅ Saved: best_hyperparameters.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4942f-f7fe-4665-95bc-f4a3c6dfdec4",
   "metadata": {},
   "source": [
    "## Save Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tuned models\n",
    "models_to_save = {\n",
    "    'logistic_regression_tuned': model_lr_tuned,\n",
    "    'knn_tuned': model_knn_tuned,\n",
    "    'linear_svc_tuned': model_svc_tuned,\n",
    "    'random_forest_entropy': model_rf2\n",
    "}\n",
    "\n",
    "for name, model in models_to_save.items():\n",
    "    filename = f'model_{name}.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"✅ Saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36420484-31a0-4300-8bf0-bd152e94ab9d",
   "metadata": {},
   "source": [
    "## Final Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL RESEARCH SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Find best overall model\n",
    "best_f1 = perf_df['F1-Score (%)'].idxmax()\n",
    "best_f1_score = perf_df.loc[best_f1, 'F1-Score (%)']\n",
    "\n",
    "best_tuned = perf_df[perf_df.index.str.contains('Tuned')]['F1-Score (%)'].idxmax()\n",
    "best_tuned_score = perf_df.loc[best_tuned, 'F1-Score (%)']\n",
    "\n",
    "print(f\"\"\"\n",
    "This comprehensive evaluation compared 10 algorithm configurations (7 baseline + 3 tuned)\n",
    "for cloud-based network intrusion detection using the UNSW-NB15 dataset.\n",
    "\n",
    "KEY FINDINGS:\n",
    "-----------\n",
    "\n",
    "1. BEST OVERALL PERFORMANCE:\n",
    "   Model: {best_f1}\n",
    "   - F1-Score: {best_f1_score:.2f}%\n",
    "   - Accuracy: {perf_df.loc[best_f1, 'Accuracy (%)']:.2f}%\n",
    "   - Precision: {perf_df.loc[best_f1, 'Precision (%)']:.2f}%\n",
    "   - Recall: {perf_df.loc[best_f1, 'Recall (%)']:.2f}%\n",
    "   - False Positive Rate: {perf_df.loc[best_f1, 'FPR (%)']:.2f}%\n",
    "\n",
    "2. BEST TUNED MODEL:\n",
    "   Model: {best_tuned}\n",
    "   - F1-Score: {best_tuned_score:.2f}%\n",
    "   - Improvement: {improvements[improvements['Algorithm'] == best_tuned.split(' (')[0]]['Improvement (%)'].values[0]:+.2f}%\n",
    "\n",
    "3. HYPERPARAMETER TUNING IMPACT:\n",
    "   Logistic Regression: {improvements.iloc[0]['Improvement (%)']:+.2f}% improvement\n",
    "   K-Nearest Neighbors:  {improvements.iloc[1]['Improvement (%)']:+.2f}% improvement\n",
    "   Linear SVC:           {improvements.iloc[2]['Improvement (%)']:+.2f}% improvement\n",
    "\n",
    "4. BEST HYPERPARAMETERS IDENTIFIED:\n",
    "   \n",
    "   Logistic Regression:\n",
    "   {lr_best_params}\n",
    "   \n",
    "   K-Nearest Neighbors:\n",
    "   {knn_best_params}\n",
    "   \n",
    "   Linear SVC:\n",
    "   {svc_best_params}\n",
    "\n",
    "5. CONFUSION MATRICES:\n",
    "   All models demonstrated strong detection capabilities with low false positive rates.\n",
    "   Confusion matrices visualizations saved for detailed analysis.\n",
    "\n",
    "CLOUD DEPLOYMENT RECOMMENDATIONS:\n",
    "--------------------------------\n",
    "- For Production: {best_f1} (best overall performance)\n",
    "- For Tuned Performance: {best_tuned} (optimized parameters)\n",
    "- All tuned models show improved F1-scores over default configurations\n",
    "\n",
    "FILES GENERATED:\n",
    "--------------\n",
    "CSV Files:\n",
    "  1. ml_algorithms_comprehensive_with_tuning.csv\n",
    "  2. performance_metrics_with_tuning.csv\n",
    "  3. hyperparameter_tuning_improvements.csv\n",
    "  4. best_hyperparameters.csv\n",
    "\n",
    "Visualizations:\n",
    "  5. confusion_matrices_all_models.png\n",
    "  6. tuning_impact_comparison.png\n",
    "  7. performance_metrics_with_tuning.png\n",
    "\n",
    "Models:\n",
    "  8. model_logistic_regression_tuned.pkl\n",
    "  9. model_knn_tuned.pkl\n",
    "  10. model_linear_svc_tuned.pkl\n",
    "  11. model_random_forest_entropy.pkl\n",
    "\n",
    "These results provide comprehensive evidence for algorithm selection based on\n",
    "both detection performance and hyperparameter optimization for cloud deployment.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
